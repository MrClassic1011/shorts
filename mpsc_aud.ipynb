{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video short_aud1.mp4.\n",
      "MoviePy - Writing audio in short_aud1TEMP_MPY_wvf_snd.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video short_aud1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready short_aud1.mp4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import pyttsx3\n",
    "from moviepy.editor import *\n",
    "from moviepy.video.VideoClip import TextClip\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to apply blur using OpenCV\n",
    "def blur_image(image):\n",
    "    return cv2.GaussianBlur(image, (25, 51), 0)  # Apply Gaussian blur, adjust kernel size as needed\n",
    "\n",
    "# Function to convert text to speech and save as an audio file\n",
    "def text_to_speech(text, filename, rate=200):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', rate)  # Set the speech rate\n",
    "    engine.save_to_file(text, filename)  # Save the speech to an audio file\n",
    "    engine.runAndWait()\n",
    "\n",
    "# Load questions from Excel\n",
    "file_path = 'GK.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Randomly choose a background and music\n",
    "backgrounds = ['bg1.mp4', 'bg2.mp4']  # List of your background video files\n",
    "music_tracks = ['music1.mp3']  # List of your music tracks\n",
    "\n",
    "# Loop through each row (question) in the DataFrame\n",
    "for idx, question_data in df.iterrows():\n",
    "    background = random.choice(backgrounds)\n",
    "    music = random.choice(music_tracks)\n",
    "    \n",
    "    # Extract data for each question\n",
    "    year = question_data['Year']\n",
    "    question = question_data['Question']\n",
    "    options = [question_data['Option1'], question_data['Option2'], question_data['Option3'], question_data['Option4']]\n",
    "    answer = question_data['Answer']\n",
    "\n",
    "    # Create audio clips for the question, options, and answer\n",
    "    question_audio = f\"question_{idx + 1}.mp3\"\n",
    "    text_to_speech(f\"Question: {question}\", question_audio)\n",
    "\n",
    "    options_audio = f\"options_{idx + 1}.mp3\"\n",
    "    options_text = \" \".join([f\"Option {i + 1}: {option}\" for i, option in enumerate(options)])\n",
    "    text_to_speech(options_text, options_audio, rate=150)  # Set speech rate to 160 (80% speed)\n",
    "\n",
    "    answer_audio = f\"answer_{idx + 1}.mp3\"\n",
    "    text_to_speech(f\"The answer is: {answer}\", answer_audio)\n",
    "\n",
    "    # Create video components\n",
    "    bg_clip1 = VideoFileClip(background).subclip(0, 20)  # Subclip to 18 seconds for short\n",
    "    bg_clip = bg_clip1.fl_image(blur_image)  # Apply blur to each frame\n",
    "\n",
    "    # 1. Year display for 3 seconds with a 3-second timer\n",
    "    year_clip = TextClip(f\"Year: {year}\", fontsize=140, color='white').set_position('center').set_duration(3)\n",
    "    timer_clip_3sec = [TextClip(str(i), fontsize=100, color='red').set_duration(1).set_position(('right', 'top')) for i in range(3, 0, -1)]\n",
    "    timer_clip_3sec = concatenate_videoclips(timer_clip_3sec)\n",
    "    year_screen = CompositeVideoClip([bg_clip.subclip(0, 3), year_clip, timer_clip_3sec]).set_duration(3)\n",
    "\n",
    "    # 2. Question display first for 14 seconds\n",
    "    question_clip = TextClip(f\"Q: {question}\", fontsize=100, color='white', size=(900, None), method='caption').set_position(('center', 200)).set_duration(14)\n",
    "    \n",
    "    # Centrally align options, wrap text, and space them dynamically\n",
    "    option_clips = []\n",
    "    start_y = 700  # Start position for options\n",
    "    for i, option in enumerate(options, 1):\n",
    "        option_text = TextClip(f\"{i}. {option}\", fontsize=80, color='white', size=(900, None), method='caption').set_position(('center', start_y + i * 200)).set_duration(14).set_start(2 + (i - 1) * 3)\n",
    "        option_clips.append(option_text)\n",
    "    \n",
    "    timer_clip_14sec = [TextClip(str(i), fontsize=100, color='red').set_duration(1).set_position(('right', 'top')) for i in range(14, 0, -1)]\n",
    "    timer_clip_14sec = concatenate_videoclips(timer_clip_14sec)\n",
    "    question_screen = CompositeVideoClip([bg_clip.subclip(0, 14), question_clip] + option_clips + [timer_clip_14sec]).set_duration(14)\n",
    "\n",
    "    # 3. Answer display for 5 seconds (new screen, no timer)\n",
    "    answer_clip = TextClip(f\"Answer: {answer}\", fontsize=100, color='green', size=(900, None), method='caption').set_position('center').set_duration(3)\n",
    "    answer_screen = CompositeVideoClip([bg_clip.subclip(0, 5), answer_clip]).set_duration(3)\n",
    "\n",
    "    # Concatenate all screens\n",
    "    final_clip = concatenate_videoclips([year_screen, question_screen, answer_screen])\n",
    "\n",
    "    # Add background music with reduced volume\n",
    "    audio_clip = AudioFileClip(music).subclip(0, final_clip.duration).volumex(0.2)  # Reduce music volume by 70%\n",
    "\n",
    "    # Add the question, options, and answer TTS audio to the video with increased volume\n",
    "    question_audio_clip = AudioFileClip(question_audio).volumex(1.5)  # Increase volume by 50%\n",
    "    options_audio_clip = AudioFileClip(options_audio).volumex(1.5)   # Increase volume by 50%\n",
    "    answer_audio_clip = AudioFileClip(answer_audio).volumex(1.5)    # Increase volume by 50%\n",
    "\n",
    "    # Merge all audio tracks (question, options, answer, and background music)\n",
    "    final_audio = CompositeAudioClip([audio_clip, question_audio_clip.set_start(3), options_audio_clip.set_start(6), answer_audio_clip.set_start(16)])\n",
    "    final_clip = final_clip.set_audio(final_audio)\n",
    "\n",
    "    # Save the final video with a unique filename for each question\n",
    "    output_filename = f\"short_aud{idx + 1}.mp4\"  # For example: short_1.mp4, short_2.mp4, etc.\n",
    "    final_clip.write_videofile(output_filename, fps=24)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
